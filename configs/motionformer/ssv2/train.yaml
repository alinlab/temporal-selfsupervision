ERM_TRAIN:
  ENABLE: True
  DATASET: Ssv2_webm # share the same data loader with timesformer
  BATCH_SIZE: 64
  EVAL_PERIOD: 1
  CHECKPOINT_PERIOD: 1
  AUTO_RESUME: True
  FP16: True
  FINETUNE: False
  NUM_ITERS: 1
DATA:
  PATH_TO_ANNOTATION: '/data/somethingv2/annotation'
  PATH_TO_JPEG: '/data/somethingv2/raw_data'
  TRAIN_SPLIT_DIR: 'train_test'
  VAL_SPLIT_DIR: 'train_test'
  MEAN: [ 0.5, 0.5, 0.5 ]
  STD: [ 0.5, 0.5, 0.5 ]
  USE_RAND_AUGMENT: True
  TRAIN_JITTER_SCALES: [ 256, 320 ]
  TRAIN_CROP_SIZE: 224
  RANDOM_FLIP: False
  INV_UNIFORM_SAMPLE: True
  REVERSE_INPUT_CHANNEL: True
  NUM_FRAMES: 8
SOLVER:
  BASE_LR: 1e-4
  LR_POLICY: steps_with_relative_lrs
  LRS: [ 1, 0.1, 0.01 ]
  STEPS: [ 0, 20, 30 ]
  MAX_EPOCH: 35
  SMOOTHING: 0.2
  MOMENTUM: 0.9
  WEIGHT_DECAY: 5e-2
  WARMUP_EPOCHS: 0.0
  OPTIMIZING_METHOD: adamw
MODEL:
  NUM_CLASSES: 174
  MODEL_NAME: motionformer_vit_base_patch16_224
  LOSS_FUNC: cross_entropy
VIT: # motionformer config
  PATCH_SIZE: 16
  PATCH_SIZE_TEMP: 1
  CHANNELS: 3
  EMBED_DIM: 768
  DEPTH: 12
  NUM_HEADS: 12
  MLP_RATIO: 4
  QKV_BIAS: True
  VIDEO_INPUT: True
  TEMPORAL_RESOLUTION: 8
  USE_MLP: True
  DROP: 0.0
  POS_DROPOUT: 0.0
  DROP_PATH: 0.2
  IM_PRETRAINED: True
  HEAD_DROPOUT: 0.0
  HEAD_ACT: tanh
  PRETRAINED_WEIGHTS: vit_1k
  ATTN_LAYER: trajectory
DATA_LOADER:
  NUM_WORKERS: 8
  PIN_MEMORY: True
TENSORBOARD:
  ENABLE: True
NUM_GPUS: 8
LOG_PERIOD: 50
RNG_SEED: 0
OUTPUT_DIR: ./experiments/motionformer_8frame
ERM_TEST:
  ENABLE: True
  DATASET: Ssv2_webm
  BATCH_SIZE: 128
